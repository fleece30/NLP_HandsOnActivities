{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Paragraphs', 'NNS'), ('are', 'VBP'), ('the', 'DT'), ('building', 'NN'), ('blocks', 'NNS'), ('of', 'IN'), ('papers', 'NNS'), ('.', '.')]\n",
      "[('Many', 'JJ'), ('students', 'NNS'), ('define', 'VBP'), ('paragraphs', 'NN'), ('in', 'IN'), ('terms', 'NNS'), ('of', 'IN'), ('length', 'NN'), (':', ':'), ('a', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('at', 'IN'), ('least', 'JJS'), ('five', 'CD'), ('sentences', 'NNS'), (',', ','), ('a', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('half', 'PDT'), ('a', 'DT'), ('page', 'NN'), ('long', 'RB'), (',', ','), ('etc', 'FW'), ('.', '.')]\n",
      "[('In', 'IN'), ('reality', 'NN'), (',', ','), ('though', 'RB'), (',', ','), ('the', 'DT'), ('unity', 'NN'), ('and', 'CC'), ('coherence', 'NN'), ('of', 'IN'), ('ideas', 'NNS'), ('among', 'IN'), ('sentences', 'NNS'), ('is', 'VBZ'), ('what', 'WP'), ('constitutes', 'VBZ'), ('a', 'DT'), ('paragraph', 'NN'), ('.', '.')]\n",
      "[('A', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('defined', 'VBN'), ('as', 'IN'), ('“', 'NN'), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('or', 'CC'), ('a', 'DT'), ('single', 'JJ'), ('sentence', 'NN'), ('that', 'WDT'), ('forms', 'VBZ'), ('a', 'DT'), ('unit', 'NN'), ('”', 'NNP'), ('(', '('), ('Lunsford', 'NNP'), ('and', 'CC'), ('Connors', 'NNP'), ('116', 'CD'), (')', ')'), ('.', '.')]\n",
      "[('Length', 'NNP'), ('and', 'CC'), ('appearance', 'NN'), ('do', 'VBP'), ('not', 'RB'), ('determine', 'VB'), ('whether', 'IN'), ('a', 'DT'), ('section', 'NN'), ('in', 'IN'), ('a', 'DT'), ('paper', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('paragraph', 'NN'), ('.', '.')]\n",
      "[('For', 'IN'), ('instance', 'NN'), (',', ','), ('in', 'IN'), ('some', 'DT'), ('styles', 'NNS'), ('of', 'IN'), ('writing', 'NN'), (',', ','), ('particularly', 'RB'), ('journalistic', 'JJ'), ('styles', 'NNS'), (',', ','), ('a', 'DT'), ('paragraph', 'NN'), ('can', 'MD'), ('be', 'VB'), ('just', 'RB'), ('one', 'CD'), ('sentence', 'NN'), ('long', 'RB'), ('.', '.')]\n",
      "[('Ultimately', 'RB'), (',', ','), ('a', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('sentence', 'NN'), ('or', 'CC'), ('group', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('that', 'WDT'), ('support', 'VBP'), ('one', 'CD'), ('main', 'JJ'), ('idea', 'NN'), ('.', '.')]\n",
      "[('In', 'IN'), ('this', 'DT'), ('handout', 'NN'), (',', ','), ('we', 'PRP'), ('will', 'MD'), ('refer', 'VB'), ('to', 'TO'), ('this', 'DT'), ('as', 'IN'), ('the', 'DT'), ('“', 'NN'), ('controlling', 'VBG'), ('idea', 'NN'), (',', ','), ('”', 'RB'), ('because', 'IN'), ('it', 'PRP'), ('controls', 'VBZ'), ('what', 'WP'), ('happens', 'VBZ'), ('in', 'IN'), ('the', 'DT'), ('rest', 'NN'), ('of', 'IN'), ('the', 'DT'), ('paragraph', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# Basic text processing pipeline\n",
    "text1 = ''' Paragraphs are the building blocks of papers. \n",
    "Many students define paragraphs in terms of length: \n",
    "a paragraph is a group of at least five sentences, \n",
    "a paragraph is half a page long, etc. In reality, though, \n",
    "the unity and coherence of ideas among sentences is what \n",
    "constitutes a paragraph. A paragraph is defined as “a group \n",
    "of sentences or a single sentence that forms a unit” \n",
    "(Lunsford and Connors 116). Length and appearance do \n",
    "not determine whether a section in a paper is a paragraph. \n",
    "For instance, in some styles of writing, particularly journalistic \n",
    "styles, a paragraph can be just one sentence long. Ultimately, a \n",
    "paragraph is a sentence or group of sentences that support one \n",
    "main idea. In this handout, we will refer to this as the “controlling \n",
    "idea,” because it controls what happens in the rest of the paragraph. '''\n",
    "\n",
    "# for text in text1:\n",
    "sentences=nltk.sent_tokenize(text1)\n",
    "for sentence in sentences:\n",
    "    words=nltk.word_tokenize(sentence)\n",
    "    tagged=nltk.pos_tag(words)\n",
    "    print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'WIN',\n",
       " 'the',\n",
       " '2020',\n",
       " 'Election',\n",
       " ',',\n",
       " 'BIG',\n",
       " '!',\n",
       " '#MAGA']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "text='We are going to WIN the 2020 Election, BIG! #MAGA'\n",
    "token = TweetTokenizer()\n",
    "token.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\\r'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Web scraping\n",
    "from urllib import request\n",
    "url=\"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response=request.urlopen(url)\n",
    "raw=response.read().decode('utf8')\n",
    "type(raw)\n",
    "len(raw)\n",
    "raw[:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens=word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 17 of 17 matches:\n",
      "n The Signal premiere. Lotsa buyers. Good luck gang listening to the pocast ne\n",
      "so going to enjoy this shower. Feels good to have worked on a trail three time\n",
      "ose not my friend. it was not a very good day so I have a lot to do tomorrow..\n",
      "Oh why cheesecake why? You looked so good evil cake. Now metamucil. Reading: \"\n",
      "utiful day so Im thinking to spend a good part of it outdoors.first stop at St\n",
      "g and ignoring my reaction to a very good friend getting fired. it's like a bi\n",
      "d HDH - url wrist sprain= damn pain. good thing it's not on my left hand. Bein\n",
      " I bet I can throw farther than her. Good luck with that dude. Sure it will al\n",
      " Choppers. first day of eid .. feels good Looking to buy a game called Shut th\n",
      "g. back from the ASLA 6 Congress. :) Good job ASLA CORE! I'm gonna need to ste\n",
      "tching the CNBC video of David Lear. Good job Sean! and now... off to Belize! \n",
      " Mom's cousin's car. this would be a good place for wifi! a hot technology to \n",
      "e Long Tail: Are dead-tree magazines good or bad for the climate? url the mida\n",
      "ortened! url www.last.fm is a really good idea Worst drive I've ever had. Sanj\n",
      " my tivoed shows I missed last week. Good day from fratres this 01.22.08! Ther\n",
      "ill have cause for regret. 01..24.08 Good Day!!! See Pope Benedict's plea for \n",
      ".. , @cleshen, everything went well. Good people! Probably have to go back to \n"
     ]
    }
   ],
   "source": [
    "#Handling tweet data\n",
    "import nltk\n",
    "f=open('tweets1.txt', 'r')\n",
    "text=f.read()\n",
    "text1=text.split()\n",
    "text2=nltk.Text(text1)\n",
    "text2.concordance(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
